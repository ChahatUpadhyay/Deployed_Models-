{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7003351-13b0-43b9-8528-352f795e6534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\chaha\\anaconda3\\lib\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: mediapipe in c:\\users\\chaha\\anaconda3\\lib\\site-packages (0.10.21)\n",
      "Requirement already satisfied: numpy in c:\\users\\chaha\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: absl-py in c:\\users\\chaha\\anaconda3\\lib\\site-packages (from mediapipe) (2.2.1)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\chaha\\anaconda3\\lib\\site-packages (from mediapipe) (23.1.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\chaha\\anaconda3\\lib\\site-packages (from mediapipe) (25.2.10)\n",
      "Requirement already satisfied: jax in c:\\users\\chaha\\anaconda3\\lib\\site-packages (from mediapipe) (0.7.1)\n",
      "Requirement already satisfied: jaxlib in c:\\users\\chaha\\anaconda3\\lib\\site-packages (from mediapipe) (0.7.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\chaha\\anaconda3\\lib\\site-packages (from mediapipe) (3.9.2)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\chaha\\anaconda3\\lib\\site-packages (from mediapipe) (4.11.0.86)\n",
      "Requirement already satisfied: protobuf<5,>=4.25.3 in c:\\users\\chaha\\anaconda3\\lib\\site-packages (from mediapipe) (4.25.3)\n",
      "Requirement already satisfied: sounddevice>=0.4.4 in c:\\users\\chaha\\anaconda3\\lib\\site-packages (from mediapipe) (0.5.3)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\chaha\\anaconda3\\lib\\site-packages (from mediapipe) (0.2.1)\n",
      "Requirement already satisfied: CFFI>=1.0 in c:\\users\\chaha\\anaconda3\\lib\\site-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
      "Requirement already satisfied: ml_dtypes>=0.5.0 in c:\\users\\chaha\\anaconda3\\lib\\site-packages (from jax->mediapipe) (0.5.1)\n",
      "Requirement already satisfied: opt_einsum in c:\\users\\chaha\\anaconda3\\lib\\site-packages (from jax->mediapipe) (3.4.0)\n",
      "Requirement already satisfied: scipy>=1.12 in c:\\users\\chaha\\anaconda3\\lib\\site-packages (from jax->mediapipe) (1.13.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\chaha\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\chaha\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\chaha\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\chaha\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\chaha\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\chaha\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\chaha\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\chaha\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\chaha\\anaconda3\\lib\\site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.21)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\chaha\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python mediapipe numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10bf7ca9-f30b-4f7b-8e7c-aaa682e2b634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries Imported Successfully!\n",
      "\n",
      "Phase 1 Setup Complete.\n"
     ]
    }
   ],
   "source": [
    "# Phase 1: Notebook Setup & Initialization (Local Jupyter Version)\n",
    "\n",
    "# Ensure libraries are installed: pip install opencv-python mediapipe numpy\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "\n",
    "print(\"Libraries Imported Successfully!\")\n",
    "\n",
    "# --- MediaPipe Pose Configuration ---\n",
    "mp_pose = mp.solutions.pose\n",
    "POSE_MODEL_COMPLEXITY = 1       # 0=lite, 1=full, 2=heavy\n",
    "POSE_SMOOTH_LANDMARKS = True    # Reduce jitter\n",
    "POSE_ENABLE_SEGMENTATION = False\n",
    "POSE_MIN_DETECTION_CONFIDENCE = 0.5\n",
    "POSE_MIN_TRACKING_CONFIDENCE = 0.5\n",
    "\n",
    "# --- Smoothing Configuration ---\n",
    "SMOOTHING_ALPHA = 0.1 # Exponential Moving Average factor (smaller=smoother, more lag)\n",
    "\n",
    "# --- Visualization Configuration ---\n",
    "COLOR_RED = (0, 0, 255)\n",
    "COLOR_GREEN = (0, 255, 0)\n",
    "COLOR_BLUE = (255, 0, 0)\n",
    "COLOR_YELLOW = (0, 255, 255)\n",
    "COLOR_WHITE = (255, 255, 255)\n",
    "COLOR_BLACK = (0, 0, 0)\n",
    "COLOR_LIGHT_BLUE = (255, 100, 0)\n",
    "COLOR_PURPLE = (255, 0, 255)\n",
    "COLOR_ORANGE = (0, 165, 255)\n",
    "FONT = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "# --- Live Feed Settings ---\n",
    "CAMERA_INDEX = 0 # Default camera index\n",
    "ESTIMATED_FPS = 30.0 # Use an estimate for initial dt, will be updated\n",
    "\n",
    "print(\"\\nPhase 1 Setup Complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "505d788a-a2ca-41ed-b1c9-b0d64ff5c0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase 3 Functions Defined.\n"
     ]
    }
   ],
   "source": [
    "# Phase 3: Biomechanical Logic Functions\n",
    "\n",
    "# --- Helper Functions ---\n",
    "def detect_stance(landmarks):\n",
    "    if landmarks is None: return \"unknown\"\n",
    "    # Assuming bowler is roughly in -Z direction relative to hip origin\n",
    "    left_shoulder_z = landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].z\n",
    "    right_shoulder_z = landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].z\n",
    "    # Shoulder closer to origin (less negative Z) is typically back shoulder\n",
    "    if left_shoulder_z > right_shoulder_z: return \"right_handed\"\n",
    "    else: return \"left_handed\"\n",
    "\n",
    "def calculate_angle_3d(a, b, c):\n",
    "    a, b, c = np.array(a), np.array(b), np.array(c)\n",
    "    ba, bc = a - b, c - b\n",
    "    norm_ba, norm_bc = np.linalg.norm(ba), np.linalg.norm(bc)\n",
    "    if norm_ba == 0 or norm_bc == 0: return 0.0\n",
    "    cosine_angle = np.clip(np.dot(ba, bc) / (norm_ba * norm_bc), -1.0, 1.0)\n",
    "    return np.degrees(np.arccos(cosine_angle))\n",
    "\n",
    "# --- Metric Functions ---\n",
    "def get_weight_transfer(landmarks, stance):\n",
    "    if landmarks is None or stance == \"unknown\": return 50.0\n",
    "    front_ankle_idx = mp_pose.PoseLandmark.LEFT_ANKLE.value if stance == \"right_handed\" else mp_pose.PoseLandmark.RIGHT_ANKLE.value\n",
    "    back_ankle_idx = mp_pose.PoseLandmark.RIGHT_ANKLE.value if stance == \"right_handed\" else mp_pose.PoseLandmark.LEFT_ANKLE.value\n",
    "    front_ankle_z = landmarks[front_ankle_idx].z\n",
    "    back_ankle_z = landmarks[back_ankle_idx].z\n",
    "    hip_center_z = 0.0\n",
    "    stance_depth = abs(front_ankle_z - back_ankle_z)\n",
    "    if stance_depth < 0.05: return 50.0 # Avoid division by zero/instability\n",
    "    hip_position_relative_to_back = hip_center_z - back_ankle_z\n",
    "    # Normalize position by stance depth along Z\n",
    "    transfer_ratio = hip_position_relative_to_back / (front_ankle_z - back_ankle_z)\n",
    "    return np.clip(transfer_ratio * 100, 0, 100)\n",
    "\n",
    "def get_front_elbow_angle(landmarks, stance):\n",
    "    if landmarks is None or stance == \"unknown\": return None\n",
    "    if stance == \"right_handed\":\n",
    "        s_idx, e_idx, w_idx = mp_pose.PoseLandmark.LEFT_SHOULDER.value, mp_pose.PoseLandmark.LEFT_ELBOW.value, mp_pose.PoseLandmark.LEFT_WRIST.value\n",
    "    else: # left_handed\n",
    "        s_idx, e_idx, w_idx = mp_pose.PoseLandmark.RIGHT_SHOULDER.value, mp_pose.PoseLandmark.RIGHT_ELBOW.value, mp_pose.PoseLandmark.RIGHT_WRIST.value\n",
    "    shoulder = [landmarks[s_idx].x, landmarks[s_idx].y, landmarks[s_idx].z]\n",
    "    elbow = [landmarks[e_idx].x, landmarks[e_idx].y, landmarks[e_idx].z]\n",
    "    wrist = [landmarks[w_idx].x, landmarks[w_idx].y, landmarks[w_idx].z]\n",
    "    return calculate_angle_3d(shoulder, elbow, wrist)\n",
    "\n",
    "def get_bat_speed_approx(current_landmarks_np, prev_landmarks_np, stance, dt):\n",
    "    if prev_landmarks_np is None or dt <= 0 or current_landmarks_np is None or stance == \"unknown\": return 0.0\n",
    "    wrist_idx = mp_pose.PoseLandmark.LEFT_WRIST.value if stance == \"right_handed\" else mp_pose.PoseLandmark.RIGHT_WRIST.value\n",
    "    current_wrist_pos = current_landmarks_np[wrist_idx]\n",
    "    prev_wrist_pos = prev_landmarks_np[wrist_idx]\n",
    "    distance = np.linalg.norm(current_wrist_pos - prev_wrist_pos) # Meters\n",
    "    return distance / dt # m/s\n",
    "\n",
    "print(\"Phase 3 Functions Defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d69840f1-9e13-4dea-8b5c-61dac737e549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MediaPipe Pose Initialized.\n",
      "Smoothed metric variables initialized.\n",
      "Camera 0 opened successfully (Default Resolution: 640x480).\n",
      "Starting live video processing loop... Press ESC in the display window to Exit.\n",
      "ESC key pressed. Exiting loop.\n",
      "Processed approximately 308 frames.\n",
      "Camera capture and windows released.\n",
      "\n",
      "Live Feed Analysis Attempt Complete.\n"
     ]
    }
   ],
   "source": [
    "# Combined Phases 2, 4, 5: Pose Engine, Visualization & Smoothing for Live Feed (Local Jupyter)\n",
    "\n",
    "# --- Initialization ---\n",
    "pose = mp_pose.Pose(\n",
    "    static_image_mode=False,\n",
    "    model_complexity=POSE_MODEL_COMPLEXITY,\n",
    "    smooth_landmarks=POSE_SMOOTH_LANDMARKS,\n",
    "    enable_segmentation=POSE_ENABLE_SEGMENTATION,\n",
    "    min_detection_confidence=POSE_MIN_DETECTION_CONFIDENCE,\n",
    "    min_tracking_confidence=POSE_MIN_TRACKING_CONFIDENCE\n",
    ")\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "print(\"MediaPipe Pose Initialized.\")\n",
    "\n",
    "# Initialize Smoothed Variables\n",
    "smoothed_transfer = 50.0\n",
    "smoothed_angle = 90.0\n",
    "smoothed_speed = 0.0\n",
    "print(\"Smoothed metric variables initialized.\")\n",
    "\n",
    "# --- Video Input Setup (Using OpenCV for Local Camera) ---\n",
    "cap = cv2.VideoCapture(CAMERA_INDEX)\n",
    "if not cap.isOpened():\n",
    "    print(f\"Error: Could not open camera with index {CAMERA_INDEX}.\")\n",
    "else:\n",
    "    # Try to get camera properties\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    # Note: cap.get(cv2.CAP_PROP_FPS) often returns 0 for webcams, use dynamic dt\n",
    "    print(f\"Camera {CAMERA_INDEX} opened successfully (Default Resolution: {frame_width}x{frame_height}).\")\n",
    "\n",
    "    prev_world_landmarks_np = None\n",
    "    frame_count = 0\n",
    "    last_time = time.time() # For dynamic dt calculation\n",
    "\n",
    "    print(\"Starting live video processing loop... Press ESC in the display window to Exit.\")\n",
    "\n",
    "    # --- Main Frame Processing Loop ---\n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            print(\"Ignoring empty camera frame.\")\n",
    "            continue # Skip processing if frame is empty\n",
    "\n",
    "        frame_count += 1\n",
    "        image = cv2.flip(image, 1) # Flip horizontally for a selfie-view display.\n",
    "\n",
    "        # Calculate dynamic delta_time\n",
    "        current_time = time.time()\n",
    "        dt = current_time - last_time\n",
    "        last_time = current_time\n",
    "        live_fps = 1.0 / dt if dt > 0 else 0\n",
    "\n",
    "        # Image Prep\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image_rgb.flags.writeable = False\n",
    "\n",
    "        # Run Pose Detection\n",
    "        results = pose.process(image_rgb)\n",
    "\n",
    "        image_rgb.flags.writeable = True\n",
    "        # Keep image in BGR format for OpenCV drawing/display\n",
    "        # image = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR) # No need to convert back if drawing on original 'image'\n",
    "\n",
    "        # Extract Landmarks\n",
    "        current_world_landmarks = None\n",
    "        current_world_landmarks_np = None\n",
    "\n",
    "        if results.pose_world_landmarks:\n",
    "            current_world_landmarks = results.pose_world_landmarks.landmark\n",
    "            current_world_landmarks_np = np.array(\n",
    "                [[lm.x, lm.y, lm.z] for lm in current_world_landmarks]\n",
    "            )\n",
    "\n",
    "            # --- Calculate Raw Metrics ---\n",
    "            stance = detect_stance(current_world_landmarks)\n",
    "            raw_transfer = get_weight_transfer(current_world_landmarks, stance)\n",
    "            raw_elbow_angle = get_front_elbow_angle(current_world_landmarks, stance)\n",
    "            raw_bat_speed = get_bat_speed_approx(current_world_landmarks_np, prev_world_landmarks_np, stance, dt)\n",
    "\n",
    "            # --- Apply Smoothing ---\n",
    "            smoothed_transfer = (SMOOTHING_ALPHA * raw_transfer) + ((1 - SMOOTHING_ALPHA) * smoothed_transfer)\n",
    "            if raw_elbow_angle is not None:\n",
    "                smoothed_angle = (SMOOTHING_ALPHA * raw_elbow_angle) + ((1 - SMOOTHING_ALPHA) * smoothed_angle)\n",
    "            smoothed_speed = (SMOOTHING_ALPHA * raw_bat_speed) + ((1 - SMOOTHING_ALPHA) * smoothed_speed)\n",
    "\n",
    "            # --- Prepare Display Values ---\n",
    "            display_transfer = smoothed_transfer\n",
    "            display_elbow_angle = smoothed_angle\n",
    "            display_bat_speed = smoothed_speed\n",
    "\n",
    "            # --- Visualization ---\n",
    "            # Draw Skeleton (on the BGR 'image')\n",
    "            if results.pose_landmarks:\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image=image, landmark_list=results.pose_landmarks, connections=mp_pose.POSE_CONNECTIONS,\n",
    "                    landmark_drawing_spec=mp_drawing.DrawingSpec(color=COLOR_GREEN, thickness=1, circle_radius=2),\n",
    "                    connection_drawing_spec=mp_drawing.DrawingSpec(color=COLOR_BLUE, thickness=1, circle_radius=1)\n",
    "                )\n",
    "\n",
    "            # Draw Metrics\n",
    "            bar_x, bar_y, bar_w, bar_h = 20, 30, 250, 25\n",
    "            fill_w = int(bar_w * (display_transfer / 100))\n",
    "            back_percent = 100 - display_transfer\n",
    "\n",
    "            cv2.rectangle(image, (bar_x, bar_y), (bar_x + bar_w, bar_y + bar_h), COLOR_BLACK, -1)\n",
    "            cv2.rectangle(image, (bar_x, bar_y), (bar_x + fill_w, bar_y + bar_h), COLOR_LIGHT_BLUE, -1)\n",
    "            cv2.putText(image, f\"Wt:\", (bar_x - 30, bar_y + 18), FONT, 0.5, COLOR_WHITE, 1, cv2.LINE_AA)\n",
    "            cv2.putText(image, f\"{back_percent:.0f}%\", (bar_x + 5, bar_y + 18), FONT, 0.5, COLOR_WHITE, 1, cv2.LINE_AA)\n",
    "            cv2.putText(image, f\"{display_transfer:.0f}%\", (bar_x + bar_w - 45, bar_y + 18), FONT, 0.5, COLOR_WHITE, 1, cv2.LINE_AA)\n",
    "            cv2.putText(image, \"BACK\", (bar_x + 40, bar_y + 18), FONT, 0.5, (180, 180, 180), 1, cv2.LINE_AA)\n",
    "            cv2.putText(image, \"FRONT\", (bar_x + bar_w - 95, bar_y + 18), FONT, 0.5, (180, 180, 180), 1, cv2.LINE_AA)\n",
    "\n",
    "            angle_text = f\"Elbow: {display_elbow_angle:.1f} deg\" if raw_elbow_angle is not None else \"Elbow: N/A\"\n",
    "            cv2.putText(image, angle_text, (bar_x, bar_y + bar_h + 30), FONT, 0.7, COLOR_GREEN, 2, cv2.LINE_AA)\n",
    "\n",
    "            speed_text = f\"Speed: {display_bat_speed:.1f} m/s\"\n",
    "            cv2.putText(image, speed_text, (bar_x, bar_y + bar_h + 60), FONT, 0.7, COLOR_YELLOW, 2, cv2.LINE_AA)\n",
    "\n",
    "            stance_text = f\"Stance: {stance.replace('_', ' ').title()}\"\n",
    "            cv2.putText(image, stance_text, (bar_x, bar_y + bar_h + 90), FONT, 0.7, COLOR_ORANGE, 2, cv2.LINE_AA)\n",
    "\n",
    "            fps_text = f\"FPS: {live_fps:.1f}\"\n",
    "            cv2.putText(image, fps_text, (frame_width - 100, 30), FONT, 0.6, COLOR_RED, 2, cv2.LINE_AA)\n",
    "\n",
    "            # --- Update Previous Landmarks ---\n",
    "            prev_world_landmarks_np = current_world_landmarks_np\n",
    "\n",
    "        else: # No pose detected\n",
    "            cv2.putText(image, \"No Pose Detected\", (10, frame_height - 10), FONT, 0.5, COLOR_RED, 1)\n",
    "            # Optionally reset smoothed values if pose is lost for a while\n",
    "            # smoothed_transfer, smoothed_angle, smoothed_speed = 50.0, 90.0, 0.0\n",
    "\n",
    "\n",
    "        # --- Display the frame using cv2.imshow ---\n",
    "        cv2.imshow('Cricket Biomechanics Analyzer - Press ESC to Exit', image)\n",
    "\n",
    "        # --- Check for exit key (ESC) ---\n",
    "        if cv2.waitKey(1) & 0xFF == 27: # waitKey(1) checks for key press for 1ms\n",
    "            print(\"ESC key pressed. Exiting loop.\")\n",
    "            break\n",
    "\n",
    "\n",
    "    # --- End of Loop ---\n",
    "    print(f\"Processed approximately {frame_count} frames.\")\n",
    "\n",
    "    # --- Release Resources ---\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    # Attempt to close any lingering windows\n",
    "    for i in range(5): cv2.waitKey(1)\n",
    "    print(\"Camera capture and windows released.\")\n",
    "\n",
    "print(\"\\nLive Feed Analysis Attempt Complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf6a83f-890f-472c-88d2-a5d80b144871",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
